{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df51c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de features - NMBE: 5\n",
      "Quantidade de features - MEC: 5\n",
      "Quantidade de features - TEXTURE: 30\n",
      "\n",
      "Avaliação no conjunto de teste:\n",
      "Acurácia: 99.25%\n",
      "F1-score: 99.24%\n",
      "Precision: 99.27%\n",
      "Recall: 99.25%\n",
      "\n",
      "Melhores hiperparâmetros encontrados:\n",
      "max_depth: 20\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 2\n",
      "n_estimators: 500\n",
      "\n",
      "Validação cruzada (4 folds):\n",
      "Fold 1: Acurácia: 99.76%, F1-score: 99.76%, Precision: 99.79%, Recall: 99.76%\n",
      "Fold 2: Acurácia: 99.76%, F1-score: 99.76%, Precision: 99.79%, Recall: 99.76%\n",
      "Fold 3: Acurácia: 99.41%, F1-score: 99.44%, Precision: 99.61%, Recall: 99.41%\n",
      "Fold 4: Acurácia: 99.29%, F1-score: 99.30%, Precision: 99.43%, Recall: 99.29%\n",
      "Fold 5: Acurácia: 99.65%, F1-score: 99.64%, Precision: 99.69%, Recall: 99.65%\n",
      "Fold 6: Acurácia: 99.53%, F1-score: 99.52%, Precision: 99.58%, Recall: 99.53%\n",
      "Fold 7: Acurácia: 99.64%, F1-score: 99.64%, Precision: 99.68%, Recall: 99.64%\n",
      "Fold 8: Acurácia: 99.41%, F1-score: 99.40%, Precision: 99.49%, Recall: 99.41%\n",
      "Fold 9: Acurácia: 99.41%, F1-score: 99.39%, Precision: 99.50%, Recall: 99.41%\n",
      "Fold 10: Acurácia: 99.64%, F1-score: 99.65%, Precision: 99.69%, Recall: 99.64%\n",
      "\n",
      "Médias:\n",
      "Acurácia Média: 99.55% (+/- 0.16%)\n",
      "F1-score Médio: 99.55% (+/- 0.15%)\n",
      "Precision Média: 99.63% (+/- 0.12%)\n",
      "Recall Médio: 99.55% (+/- 0.16%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "database = 'MED115'\n",
    "\n",
    "directory = os.path.join(os.getcwd(), database)\n",
    "directory_nmbe = os.path.join(directory, 'nmbe.db')\n",
    "directory_mec = os.path.join(directory, 'mec.db')\n",
    "directory_texture = os.path.join(directory, 'texture.db')\n",
    "\n",
    "# Carregar dicionários\n",
    "with open(directory_nmbe, 'rb') as file:\n",
    "    dict_nmbe = pickle.load(file)\n",
    "\n",
    "with open(directory_mec, 'rb') as file:\n",
    "    dict_mec = pickle.load(file)\n",
    "\n",
    "with open(directory_texture, 'rb') as file:\n",
    "    dict_texture = pickle.load(file)\n",
    "\n",
    "# Printar quantidades de features\n",
    "sample_nmbe = next(iter(dict_nmbe.values()))\n",
    "sample_mec = next(iter(dict_mec.values()))\n",
    "sample_texture = next(iter(dict_texture.values()))\n",
    "\n",
    "print(\"Quantidade de features - NMBE:\", len(sample_nmbe[1:]))\n",
    "print(\"Quantidade de features - MEC:\", len(sample_mec[1:]))\n",
    "print(\"Quantidade de features - TEXTURE:\", len(sample_texture[1:]))\n",
    "\n",
    "# Concatenar dicionários\n",
    "concatenated_dict = {}\n",
    "for d in [dict_nmbe,\n",
    "          dict_mec, \n",
    "          dict_texture\n",
    "         ]:\n",
    "    for filename, features in d.items():\n",
    "        filename_base = os.path.splitext(filename)[0]\n",
    "        if filename_base in concatenated_dict:\n",
    "            concatenated_dict[filename_base] = np.concatenate((concatenated_dict[filename_base], features[1:]))\n",
    "        else:\n",
    "            concatenated_dict[filename_base] = features\n",
    "\n",
    "# Separar labels e features\n",
    "data_labels = [sample[0] for sample in concatenated_dict.values()]\n",
    "data_features = [sample[1:] for sample in concatenated_dict.values()]\n",
    "\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "data_features = scaler.fit_transform(data_features)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=40)\n",
    "data_features = pca.fit_transform(data_features)\n",
    "\n",
    "# Treino/teste split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_features, data_labels, test_size=0.3, shuffle=True, stratify=data_labels\n",
    ")\n",
    "\n",
    "# Hiperparâmetros para o GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# GridSearch com validação cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(class_weight='balanced'),\n",
    "    param_grid,\n",
    "    cv=4,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\nAvaliação no conjunto de teste:\")\n",
    "print(f\"Acurácia: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1-score: {f1 * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "\n",
    "# Printar melhores hiperparâmetros\n",
    "print(\"\\nMelhores hiperparâmetros encontrados:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Validação cruzada manual com o melhor modelo\n",
    "kf = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "acuracias = []\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for train_index, test_index in kf.split(data_features, data_labels):\n",
    "    X_train_cv, X_test_cv = np.array(data_features)[train_index], np.array(data_features)[test_index]\n",
    "    y_train_cv, y_test_cv = np.array(data_labels)[train_index], np.array(data_labels)[test_index]\n",
    "\n",
    "    best_model.fit(X_train_cv, y_train_cv)\n",
    "    y_pred_cv = best_model.predict(X_test_cv)\n",
    "\n",
    "    acuracias.append(accuracy_score(y_test_cv, y_pred_cv))\n",
    "    f1_scores.append(f1_score(y_test_cv, y_pred_cv, average='weighted'))\n",
    "    precisions.append(precision_score(y_test_cv, y_pred_cv, average='weighted'))\n",
    "    recalls.append(recall_score(y_test_cv, y_pred_cv, average='weighted'))\n",
    "\n",
    "# Métricas médias e desvios-padrão\n",
    "print(\"\\nValidação cruzada (4 folds):\")\n",
    "for i, (a, f, p, r) in enumerate(zip(acuracias, f1_scores, precisions, recalls)):\n",
    "    print(f\"Fold {i+1}: Acurácia: {a*100:.2f}%, F1-score: {f*100:.2f}%, Precision: {p*100:.2f}%, Recall: {r*100:.2f}%\")\n",
    "\n",
    "print(\"\\nMédias:\")\n",
    "print(f\"Acurácia Média: {np.mean(acuracias) * 100:.2f}% (+/- {np.std(acuracias) * 100:.2f}%)\")\n",
    "print(f\"F1-score Médio: {np.mean(f1_scores) * 100:.2f}% (+/- {np.std(f1_scores) * 100:.2f}%)\")\n",
    "print(f\"Precision Média: {np.mean(precisions) * 100:.2f}% (+/- {np.std(precisions) * 100:.2f}%)\")\n",
    "print(f\"Recall Médio: {np.mean(recalls) * 100:.2f}% (+/- {np.std(recalls) * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435382c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
